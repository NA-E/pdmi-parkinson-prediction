{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "58dd0214",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mixed Effect Model Implementation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm \n",
    "from statsmodels.regression.mixed_linear_model import MixedLM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import KFold, ParameterGrid\n",
    "\n",
    "def prepare_temporal_data(data, visit_col='visit', target_col='UPDRS3_total'):\n",
    "    visit_order = {\n",
    "        'BL': 0, 'V04': 1, 'V06': 2, \n",
    "        'V08': 3, 'V10': 4, 'V12': 5\n",
    "    }\n",
    "    \n",
    "    data_copy = data.copy()\n",
    "    data_copy['visit_order'] = data_copy[visit_col].map(visit_order)\n",
    "    \n",
    "    # Get the last visit for each patient\n",
    "    last_visit_mask = data_copy[visit_col] == data_copy.groupby(level='PATNO')[visit_col].transform('max')\n",
    "    \n",
    "    # X: all visits EXCEPT last visit\n",
    "    X = data_copy[~last_visit_mask].copy()\n",
    "    X = X.drop(columns=[target_col])\n",
    "    \n",
    "    # y: ONLY last visit's target\n",
    "    y_last = data_copy[last_visit_mask][target_col]\n",
    "    \n",
    "    # Repeat y values to match X structure\n",
    "    y = pd.Series(index=X.index)\n",
    "    for pat in X.index.get_level_values('PATNO').unique():\n",
    "        y[X.index.get_level_values('PATNO') == pat] = y_last[pat]\n",
    "    \n",
    "    print(f\"X shape: {X.shape}\")\n",
    "    print(f\"y shape: {y.shape}\")\n",
    "    \n",
    "    # Drop non-numeric columns and add constant\n",
    "    X_subset = X.drop(['visit', 'visit_order'], axis=1)\n",
    "    X_subset = sm.add_constant(X_subset)\n",
    "    \n",
    "    try:\n",
    "        # Fit model\n",
    "        model = MixedLM(\n",
    "            endog=y,\n",
    "            exog=X_subset,\n",
    "            groups=X.index.get_level_values('PATNO')\n",
    "        ).fit()\n",
    "        print(\"Model fitted successfully\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error in fitting model: {str(e)}\")\n",
    "        print(\"\\nDebug info:\")\n",
    "        print(\"X_subset shape:\", X_subset.shape)\n",
    "        print(\"y shape:\", y.shape)\n",
    "        print(\"Number of unique patients in X:\", len(X.index.get_level_values('PATNO').unique()))\n",
    "        print(\"Number of unique patients in y:\", len(y.index.unique()))\n",
    "        return None\n",
    "\n",
    "def run_longitudinal_experiments(data_dict, visit_col='visit', target_col='UPDRS3_total'):\n",
    "    \"\"\"\n",
    "    Main function to run longitudinal experiments\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for dataset_name, data in data_dict.items():\n",
    "        print(f\"\\nProcessing dataset: {dataset_name}\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"Initial data shape: {data.shape}\")\n",
    "        \n",
    "        # Prepare temporal data\n",
    "        X, y = prepare_temporal_data(data, visit_col, target_col)\n",
    "        print('After prepare_temporal_data:')\n",
    "        print(f'X shape: {X.shape}, y shape: {y.shape}')\n",
    "        print(f'X index unique PATNOs: {len(X.index.get_level_values(\"PATNO\").unique())}')\n",
    "\n",
    "        # Split patients into train/test sets\n",
    "        unique_patients = X.index.get_level_values('PATNO').unique()\n",
    "        print(f\"\\nBefore split - unique patients: {len(unique_patients)}\")\n",
    "        \n",
    "        train_patients, test_patients = train_test_split(unique_patients, \n",
    "                                               test_size=0.2, \n",
    "                                               random_state=42)\n",
    "        print(f\"After split - train patients: {len(train_patients)}, test patients: {len(test_patients)}\")\n",
    "\n",
    "        # Split data based on patients\n",
    "        X_train = X[X.index.get_level_values('PATNO').isin(train_patients)]\n",
    "        X_test = X[X.index.get_level_values('PATNO').isin(test_patients)]\n",
    "        y_train = y[y.index.isin(X_train.index)]\n",
    "        y_test = y[y.index.isin(X_test.index)]\n",
    "        \n",
    "        print(\"\\nAfter patient-based splitting:\")\n",
    "        print(f\"X_train shape: {X_train.shape}, X_test shape: {X_test.shape}\")\n",
    "        print(f\"y_train shape: {y_train.shape}, y_test shape: {y_test.shape}\")\n",
    "        \n",
    "        # Perform grid search using training data\n",
    "        best_model, best_params, grid_results = grid_search_mixed_lm(\n",
    "            X_train, y_train\n",
    "        )\n",
    "        \n",
    "        # ... rest of the function ...\n",
    "\n",
    "def grid_search_mixed_lm(X, y, n_folds=5):\n",
    "    \"\"\"\n",
    "    Simplified Mixed LM for longitudinal data\n",
    "    \"\"\"\n",
    "    print(\"X index:\", X.index)\n",
    "    print(\"y index:\", y.index)\n",
    "    print(\"\\nX shape:\", X.shape)\n",
    "    print(\"y shape:\", y.shape)\n",
    "    \n",
    "    # Drop non-numeric columns\n",
    "    X_subset = X.drop(['visit', 'visit_order'], axis=1)\n",
    "    \n",
    "    # Add constant\n",
    "    X_subset = sm.add_constant(X_subset)\n",
    "    \n",
    "    try:\n",
    "        # Fit a single model\n",
    "        test_model = MixedLM(\n",
    "            endog=y,\n",
    "            exog=X_subset,\n",
    "            groups=X.index.get_level_values('PATNO')\n",
    "        ).fit()\n",
    "        \n",
    "        return test_model, {'features': X_subset.columns.tolist()}, None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError fitting model: {str(e)}\")\n",
    "        raise ValueError(\"Could not fit model with basic configuration\")\n",
    "        \n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        'mae': mean_absolute_error(y_true, y_pred),\n",
    "        'rmse': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'r2': r2_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "def calculate_temporal_metrics(model, test_data):\n",
    "    return {\n",
    "        'icc': calculate_icc(model),  # Intraclass Correlation Coefficient\n",
    "        'consistent_effects': assess_temporal_consistency(model),\n",
    "        'longitudinal_reliability': calculate_reliability(model)\n",
    "    }\n",
    "\n",
    "def calculate_diagnostic_metrics(model):\n",
    "    return {\n",
    "        'aic': model.aic,\n",
    "        'bic': model.bic,\n",
    "        'log_likelihood': model.llf,\n",
    "        'condition_number': model.cond_no,\n",
    "        'convergence_info': model.converged\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12b95744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_visits_df_long(main_dataframe, visits):\n",
    "    combined_dfs = {}\n",
    "    \n",
    "    # Start by reshaping the baseline (BL) into long format\n",
    "    bl_columns = [col for col in main_dataframe.columns if 'BL' in col[1]]\n",
    "    bl_df = main_dataframe.loc[:, bl_columns].copy()\n",
    "    bl_df.columns = bl_df.columns.droplevel(1)  # Drop the 'BL' level from columns\n",
    "    bl_df['visit'] = 'BL'\n",
    "    \n",
    "    combined_so_far_df = bl_df\n",
    "    combined_dfs['BL'] = bl_df\n",
    "    \n",
    "    for i in range(len(visits)):\n",
    "        # Get columns for the current visit\n",
    "        visit = visits[i]\n",
    "        visit_columns = [col for col in main_dataframe.columns if visit in col[1]]\n",
    "        \n",
    "        # Create the DataFrame for the current visit\n",
    "        visit_df = main_dataframe.loc[:, visit_columns].copy()\n",
    "        visit_df.columns = visit_df.columns.droplevel(1) \n",
    "        visit_df['visit'] = visit \n",
    "        \n",
    "        combined_df = pd.concat([combined_so_far_df, visit_df], axis=0)\n",
    "        \n",
    "        combined_name = 'BL_' + '_'.join(visits[:i+1])\n",
    "    \n",
    "        combined_dfs[combined_name] = combined_df\n",
    "        \n",
    "        combined_so_far_df = combined_df\n",
    "    \n",
    "    return combined_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be6a64de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_updrs_columns(dataframe):\n",
    "    updrs_columns = {\n",
    "        'UPDRS1': ['NP1COG', 'NP1HALL', 'NP1DPRS', 'NP1ANXS', 'NP1APAT', 'NP1DDS', 'NP1SLPN', 'NP1SLPD', 'NP1PAIN', 'NP1URIN', 'NP1CNST', 'NP1LTHD', 'NP1FATG'],\n",
    "        'UPDRS2': ['NP2SPCH', 'NP2SALV', 'NP2SWAL', 'NP2EAT', 'NP2DRES', 'NP2HYGN', 'NP2HWRT', 'NP2HOBB', 'NP2TURN', 'NP2TRMR', 'NP2RISE', 'NP2WALK', 'NP2FREZ'],\n",
    "        'UPDRS3': ['NP3SPCH', 'NP3FACXP', 'NP3RIGN', 'NP3RIGRU', 'NP3RIGLU', 'NP3RIGLL', 'NP3FTAPR', 'NP3FTAPL', 'NP3HMOVR', 'NP3HMOVL', 'NP3PRSPR', 'NP3PRSPL', 'NP3TTAPR', 'NP3TTAPL', 'NP3LGAGR', 'NP3LGAGL', 'NP3RISNG', 'NP3GAIT', 'NP3FRZGT', 'NP3PSTBL', 'NP3POSTR', 'NP3BRADY', 'NP3PTRMR', 'NP3PTRML', 'NP3KTRMR', 'NP3KTRML', 'NP3RTARU', 'NP3RTALU', 'NP3RTARL', 'NP3RTALL', 'NP3RTALJ', 'NP3RTCON', 'NHY']\n",
    "    }\n",
    "    \n",
    "    # Ensure all UPDRS columns exist in the dataframe\n",
    "    existing_updrs3_columns = [col for col in updrs_columns['UPDRS3'] if col in dataframe.columns]\n",
    "    \n",
    "    dataframe['UPDRS3_total'] = dataframe[existing_updrs3_columns].sum(axis=1)\n",
    "    \n",
    "    columns_to_drop = []\n",
    "    for key in updrs_columns:\n",
    "        columns_to_drop.extend([col for col in updrs_columns[key] if col in dataframe.columns])\n",
    "    \n",
    "    dataframe = dataframe.drop(columns=columns_to_drop)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "185ff8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_updrs_processing_to_combined_dfs(combined_dfs):\n",
    "    processed_dfs = {}\n",
    "    \n",
    "    for key, df in combined_dfs.items():\n",
    "        processed_df = process_updrs_columns(df)\n",
    "        \n",
    "        processed_dfs[key] = processed_df\n",
    "    \n",
    "    return processed_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1107f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_visits = {\n",
    "    'BL': 'V04',\n",
    "    'BL_V04': 'V06',\n",
    "    'BL_V04_V06': 'V08',\n",
    "    'BL_V04_V06_V08': 'V10',\n",
    "    'BL_V04_V06_V08_V10': 'V12'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62bc89f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_rnn_data_with_all_columns(processed_combined_dfs, patient_col='PATNO', updrs_col='UPDRS3_total', visit_col='visit'):\n",
    "\n",
    "\n",
    "    X = []  # List to hold input sequences\n",
    "    y = []  # List to hold target values (next visit's UPDRS3_total)\n",
    "    \n",
    "    for key, df in processed_combined_dfs.items():\n",
    "        target_visit = target_visits.get(key)\n",
    "        \n",
    "        df = df.sort_values(by=[patient_col, visit_col])\n",
    "        \n",
    "        # Create a DataFrame holding the target visit's UPDRS3_total values for each patient\n",
    "        target_df = df[df[visit_col] == target_visit][[patient_col, updrs_col]]\n",
    "        \n",
    "        # Drop rows corresponding to the target visit from the original DataFrame\n",
    "        df = df[df[visit_col] != target_visit]\n",
    "        \n",
    "        # Drop columns that are not needed as input (PATNO, visit, and UPDRS3_total)\n",
    "        input_columns = df.drop(columns=[patient_col, updrs_col, visit_col], errors='ignore').columns\n",
    "        \n",
    "        # Group data by patient\n",
    "        grouped = df.groupby(patient_col)\n",
    "        \n",
    "        # Loop through each patient\n",
    "        for patient_id, group in grouped:\n",
    "            # Extract the input features as a NumPy array\n",
    "            input_values = group[input_columns].values\n",
    "            \n",
    "            # Find the corresponding target value for this patient from the target_df\n",
    "            target_value = target_df[target_df[patient_col] == patient_id][updrs_col].values[0]\n",
    "            \n",
    "            # Add the input sequence and corresponding target value to the lists\n",
    "            X.append(input_values)\n",
    "            y.append(target_value)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "480427d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_target_columns(dataframe):\n",
    "    \n",
    "    updrs1_columns = ['NP1COG', 'NP1HALL', 'NP1DPRS', 'NP1ANXS', 'NP1APAT', 'NP1DDS',\n",
    "                      'NP1SLPN', 'NP1SLPD', 'NP1PAIN', 'NP1URIN', 'NP1CNST', 'NP1LTHD', 'NP1FATG']\n",
    "    updrs2_columns = [\"NP2SPCH\", \"NP2SALV\", \"NP2SWAL\", \"NP2EAT\", \"NP2DRES\", \"NP2HYGN\", \"NP2HWRT\",\n",
    "                  \"NP2HOBB\", \"NP2TURN\", \"NP2TRMR\", \"NP2RISE\", \"NP2WALK\", \"NP2FREZ\"]\n",
    "    \n",
    "# \"['CMEDTM', 'EXAMTM', 'PN3RIGRL', 'DYSKPRES', 'DYSKIRAT', 'ANNUAL_TIME_BTW_DOSE_NUPDRS', 'ON_OFF_DOSE', 'PD_MED_USE']\n",
    "    updrs3_columns = [\"NP3SPCH\", \"NP3FACXP\", \"NP3RIGN\", \"NP3RIGRU\", \"NP3RIGLU\", \"NP3RIGLL\",\n",
    "                  \"NP3FTAPR\", \"NP3FTAPL\", \"NP3HMOVR\", \"NP3HMOVL\", \"NP3PRSPR\", \"NP3PRSPL\", \"NP3TTAPR\", \"NP3TTAPL\", \"NP3LGAGR\",\n",
    "                  \"NP3LGAGL\", \"NP3RISNG\", \"NP3GAIT\", \"NP3FRZGT\", \"NP3PSTBL\", \"NP3POSTR\", \"NP3BRADY\", \"NP3PTRMR\", \"NP3PTRML\",\n",
    "                  \"NP3KTRMR\", \"NP3KTRML\", \"NP3RTARU\", \"NP3RTALU\", \"NP3RTARL\", \"NP3RTALL\", \"NP3RTALJ\", \"NP3RTCON\",\n",
    "                   \"NHY\"]\n",
    "\n",
    "#     updrs4_columns = [\"NP4WDYSK\", \"NP4DYSKI\", \"NP4OFF\", \"NP4FLCTI\", \"NP4FLCTX\", \"NP4DYSTN\"]\n",
    "    target_dataframe = pd.DataFrame(index=dataframe.index)\n",
    "    target_dataframe['UPDRS1'] = dataframe[updrs1_columns].sum(axis=1)\n",
    "    target_dataframe['UPDRS2'] = dataframe[updrs2_columns].sum(axis=1)\n",
    "    target_dataframe['UPDRS3'] = dataframe[updrs3_columns].sum(axis=1)\n",
    "#     target_dataframe['UPDRS4'] = dataframe[updrs4_columns].sum(axis=1)\n",
    "\n",
    "    \n",
    "    dataframe = dataframe.drop(columns=updrs1_columns + updrs2_columns + updrs3_columns)\n",
    "    \n",
    "    return target_dataframe, dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d38a8392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def filter_bl_and_target(df, target_visit):\n",
    "    \"\"\"\n",
    "    Filters the DataFrame to keep all data from the baseline (BL) visit and the UPDRS \n",
    "    score from the specified target visit.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame with multi-index columns (features and visits).\n",
    "    target_visit (str): The visit for which the UPDRS score is to be retained (e.g., 'V04').\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: A new DataFrame containing the BL data and the UPDRS score for the target visit.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Keep all baseline (BL) data\n",
    "    bl_data = df.xs('BL', level=1, axis=1)\n",
    "\n",
    "    # Keep the UPDRS score for the specified visit (e.g., V04)\n",
    "    if ('UPDRS', target_visit) in df.columns:\n",
    "        updrs_target = df[('UPDRS', target_visit)].rename(f'UPDRS_{target_visit}')\n",
    "    else:\n",
    "        raise ValueError(f\"UPDRS score for visit {target_visit} not found in the DataFrame.\")\n",
    "    \n",
    "    # Combine the BL data and UPDRS target into a single DataFrame\n",
    "    result_df = pd.concat([bl_data, updrs_target], axis=1)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "170fa245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset for RNN\n",
    "def prepare_data(data, target_visit):\n",
    "    visit_sequence = ['BL', 'V04', 'V06']\n",
    "    target_index = visit_sequence.index(target_visit)\n",
    "    required_visits = visit_sequence[:target_index+1]\n",
    "    \n",
    "    X, y = [], []\n",
    "    for patient_id, group in data.groupby('PATNO'):\n",
    "        group = group.set_index('visit')\n",
    "        if all(visit in group.index for visit in required_visits):\n",
    "            features = []\n",
    "            for visit in required_visits:\n",
    "                visit_features = group.loc[visit, ['Feature1', 'Feature2']].values\n",
    "                if visit != target_visit:\n",
    "                    visit_target = group.loc[visit, 'Target']\n",
    "                    features.extend(np.concatenate((visit_features, [visit_target])))\n",
    "                else:\n",
    "                    features.extend(visit_features)\n",
    "            X.append(features)\n",
    "            y.append(group.loc[target_visit, 'Target'])\n",
    "    return np.array(X), np.array(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e14a3c06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
