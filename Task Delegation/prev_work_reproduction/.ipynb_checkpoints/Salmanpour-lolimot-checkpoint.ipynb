{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aba26639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitudinal Dataset:\n",
      "    patient_id  visit  feature_1  feature_2  feature_3  mds_updrs\n",
      "0            1      1   0.374540   0.950714   0.731994  30.461377\n",
      "1            1      2   0.598658   0.156019   0.155995   9.767211\n",
      "2            1      3   0.058084   0.866176   0.601115  68.423303\n",
      "3            1      4   0.708073   0.020584   0.969910  44.015249\n",
      "4            2      1   0.832443   0.212339   0.181825  12.203823\n",
      "5            2      2   0.183405   0.304242   0.524756  49.517691\n",
      "6            2      3   0.431945   0.291229   0.611853   3.438852\n",
      "7            2      4   0.139494   0.292145   0.366362  90.932040\n",
      "8            3      1   0.456070   0.785176   0.199674  25.877998\n",
      "9            3      2   0.514234   0.592415   0.046450  66.252228\n",
      "10           3      3   0.607545   0.170524   0.065052  31.171108\n",
      "11           3      4   0.948886   0.965632   0.808397  52.006802\n",
      "\n",
      "Model Evaluation:\n",
      "Mean Squared Error: 0.0000\n",
      "\n",
      "Tree Structure:\n",
      "Node: Feature 0 <= 0.4852\n",
      "  Node: Feature 0 <= 0.1614\n",
      "    Leaf: Depth=2, MSE=3059.9221\n",
      "    Leaf: Depth=2, MSE=3186.1932\n",
      "  Node: Feature 2 <= 0.1105\n",
      "    Leaf: Depth=2, MSE=1164.8822\n",
      "    Leaf: Depth=2, MSE=917.5427\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "class LoLiMoTNode:\n",
    "    def __init__(self):\n",
    "        self.linear_model = None      # Linear model in this region (only for leaf nodes)\n",
    "        self.split_feature = None     # Feature used to split this node\n",
    "        self.split_value = None       # Value of the feature for splitting\n",
    "        self.left = None              # Left child node\n",
    "        self.right = None             # Right child node\n",
    "\n",
    "class LoLiMoT:\n",
    "    def __init__(self, max_depth=10, min_error=1e-3, min_samples_split=10):\n",
    "        \"\"\"\n",
    "        Initializes the LoLiMoT model.\n",
    "\n",
    "        Parameters:\n",
    "        - max_depth (int): Maximum depth of the tree.\n",
    "        - min_error (float): Minimum MSE improvement required to make a split.\n",
    "        - min_samples_split (int): Minimum number of samples required to consider splitting a node.\n",
    "        \"\"\"\n",
    "        self.max_depth = max_depth\n",
    "        self.min_error = min_error\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.root = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fits the LoLiMoT model to the data.\n",
    "\n",
    "        Parameters:\n",
    "        - X (np.ndarray): Feature matrix.\n",
    "        - y (np.ndarray): Target vector.\n",
    "        \"\"\"\n",
    "        # Start recursion with the whole dataset\n",
    "        self.root = self._fit_recursive(X, y, depth=0)\n",
    "\n",
    "    def _fit_recursive(self, X, y, depth):\n",
    "        # Create a new node\n",
    "        node = LoLiMoTNode()\n",
    "\n",
    "        # Fit a linear model for the current node\n",
    "        linear_model = LinearRegression()\n",
    "        linear_model.fit(X, y)\n",
    "\n",
    "        # Predict the output and calculate the error\n",
    "        y_pred = linear_model.predict(X)\n",
    "        error = mean_squared_error(y, y_pred)\n",
    "\n",
    "        # Stopping criteria:\n",
    "        # - Max depth reached\n",
    "        # - Error is below the threshold\n",
    "        # - Not enough samples to split\n",
    "        if (\n",
    "            depth >= self.max_depth\n",
    "            or error <= self.min_error\n",
    "            or X.shape[0] < self.min_samples_split\n",
    "        ):\n",
    "            node.linear_model = linear_model  # Assign model only to leaf nodes\n",
    "            return node\n",
    "\n",
    "        # Find the best feature and value to split the data\n",
    "        best_split_feature, best_split_value, best_error = self._find_best_split(X, y, linear_model)\n",
    "\n",
    "        # If no significant improvement is found, make this a leaf node\n",
    "        if best_split_feature is None or best_error >= error:\n",
    "            node.linear_model = linear_model  # Assign model only to leaf nodes\n",
    "            return node\n",
    "\n",
    "        # Otherwise, split the data and recurse\n",
    "        node.split_feature = best_split_feature\n",
    "        node.split_value = best_split_value\n",
    "\n",
    "        left_indices = X[:, best_split_feature] <= best_split_value\n",
    "        right_indices = X[:, best_split_feature] > best_split_value\n",
    "\n",
    "        # Ensure that both splits have enough samples\n",
    "        if left_indices.sum() < self.min_samples_split or right_indices.sum() < self.min_samples_split:\n",
    "            node.linear_model = linear_model  # Assign model only to leaf nodes\n",
    "            return node\n",
    "\n",
    "        node.left = self._fit_recursive(X[left_indices], y[left_indices], depth + 1)\n",
    "        node.right = self._fit_recursive(X[right_indices], y[right_indices], depth + 1)\n",
    "\n",
    "        return node\n",
    "\n",
    "    def _find_best_split(self, X, y, current_model):\n",
    "        \"\"\"\n",
    "        Finds the best feature and value to split the data to minimize MSE.\n",
    "\n",
    "        Parameters:\n",
    "        - X (np.ndarray): Feature matrix.\n",
    "        - y (np.ndarray): Target vector.\n",
    "        - current_model (LinearRegression): Linear model of the current node.\n",
    "\n",
    "        Returns:\n",
    "        - best_feature (int): Index of the best feature to split on.\n",
    "        - best_value (float): Value of the feature to split on.\n",
    "        - best_error (float): The combined MSE after the split.\n",
    "        \"\"\"\n",
    "        # Initialize variables to store the best split\n",
    "        best_feature = None\n",
    "        best_value = None\n",
    "        best_error = float('inf')\n",
    "\n",
    "        n_features = X.shape[1]\n",
    "\n",
    "        for feature_idx in range(n_features):\n",
    "            # Sort the data by the current feature\n",
    "            sorted_indices = np.argsort(X[:, feature_idx])\n",
    "            X_sorted, y_sorted = X[sorted_indices], y[sorted_indices]\n",
    "\n",
    "            # Try every possible split point\n",
    "            for i in range(1, len(X_sorted)):\n",
    "                # Skip if the current value is the same as the previous to avoid redundant splits\n",
    "                if X_sorted[i, feature_idx] == X_sorted[i - 1, feature_idx]:\n",
    "                    continue\n",
    "\n",
    "                split_value = (X_sorted[i, feature_idx] + X_sorted[i - 1, feature_idx]) / 2\n",
    "\n",
    "                # Split the data into two parts based on the split_value\n",
    "                left_indices = X[:, feature_idx] <= split_value\n",
    "                right_indices = X[:, feature_idx] > split_value\n",
    "\n",
    "                # Ensure both splits have enough samples\n",
    "                if left_indices.sum() < self.min_samples_split or right_indices.sum() < self.min_samples_split:\n",
    "                    continue\n",
    "\n",
    "                # Fit linear models on both splits\n",
    "                left_model = LinearRegression()\n",
    "                right_model = LinearRegression()\n",
    "\n",
    "                left_model.fit(X[left_indices], y[left_indices])\n",
    "                right_model.fit(X[right_indices], y[right_indices])\n",
    "\n",
    "                # Calculate the combined error\n",
    "                y_left_pred = left_model.predict(X[left_indices])\n",
    "                y_right_pred = right_model.predict(X[right_indices])\n",
    "\n",
    "                error_left = mean_squared_error(y[left_indices], y_left_pred)\n",
    "                error_right = mean_squared_error(y[right_indices], y_right_pred)\n",
    "\n",
    "                combined_error = (error_left * left_indices.sum() + error_right * right_indices.sum()) / len(y)\n",
    "\n",
    "                # Update the best split if this one is better\n",
    "                if combined_error < best_error:\n",
    "                    best_feature = feature_idx\n",
    "                    best_value = split_value\n",
    "                    best_error = combined_error\n",
    "\n",
    "        return best_feature, best_value, best_error\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predicts the target values for the input samples.\n",
    "\n",
    "        Parameters:\n",
    "        - X (np.ndarray): Feature matrix.\n",
    "\n",
    "        Returns:\n",
    "        - predictions (np.ndarray): Predicted target values.\n",
    "        \"\"\"\n",
    "        # Predict the output for each sample in X\n",
    "        return np.array([self._predict_recursive(x, self.root) for x in X])\n",
    "\n",
    "    def _predict_recursive(self, x, node):\n",
    "        \"\"\"\n",
    "        Recursively traverses the tree to make a prediction for a single sample.\n",
    "\n",
    "        Parameters:\n",
    "        - x (np.ndarray): Single sample feature vector.\n",
    "        - node (LoLiMoTNode): Current node in the tree.\n",
    "\n",
    "        Returns:\n",
    "        - prediction (float): Predicted target value.\n",
    "        \"\"\"\n",
    "        # If this is a leaf node, use the linear model to predict\n",
    "        if node.linear_model is not None:\n",
    "            return node.linear_model.predict([x])[0]\n",
    "\n",
    "        # Otherwise, recurse into the left or right child\n",
    "        if x[node.split_feature] <= node.split_value:\n",
    "            return self._predict_recursive(x, node.left)\n",
    "        else:\n",
    "            return self._predict_recursive(x, node.right)\n",
    "\n",
    "    def print_tree(self, node=None, depth=0):\n",
    "        \"\"\"\n",
    "        Optional: Prints the tree structure for debugging purposes.\n",
    "\n",
    "        Parameters:\n",
    "        - node (LoLiMoTNode): Current node in the tree.\n",
    "        - depth (int): Current depth in the tree.\n",
    "        \"\"\"\n",
    "        if node is None:\n",
    "            node = self.root\n",
    "\n",
    "        indent = \"  \" * depth\n",
    "        if node.linear_model is not None:\n",
    "            print(f\"{indent}Leaf: Depth={depth}, MSE={mean_squared_error(y, node.linear_model.predict(X)):.4f}\")\n",
    "            return\n",
    "\n",
    "        print(f\"{indent}Node: Feature {node.split_feature} <= {node.split_value:.4f}\")\n",
    "        if node.left:\n",
    "            self.print_tree(node.left, depth + 1)\n",
    "        if node.right:\n",
    "            self.print_tree(node.right, depth + 1)\n",
    "\n",
    "# Example Usage with the Provided Longitudinal Dataset\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create the longitudinal dataset\n",
    "    np.random.seed(42)\n",
    "\n",
    "    n_patients = 3\n",
    "    n_visits = 4\n",
    "    n_features = 3\n",
    "\n",
    "    patient_ids = np.repeat(np.arange(1, n_patients + 1), n_visits)\n",
    "    visit_numbers = np.tile(np.arange(1, n_visits + 1), n_patients)\n",
    "    feature_data = np.random.rand(n_patients * n_visits, n_features)\n",
    "    mds_updrs = np.random.rand(n_patients * n_visits) * 100\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        data=np.column_stack([patient_ids, visit_numbers, feature_data, mds_updrs]),\n",
    "        columns=['patient_id', 'visit', 'feature_1', 'feature_2', 'feature_3', 'mds_updrs']\n",
    "    )\n",
    "\n",
    "    # Convert patient_id and visit to integers\n",
    "    df['patient_id'] = df['patient_id'].astype(int)\n",
    "    df['visit'] = df['visit'].astype(int)\n",
    "\n",
    "    # Display the dataframe\n",
    "    print(\"Longitudinal Dataset:\")\n",
    "    print(df)\n",
    "\n",
    "    # Prepare the data for training\n",
    "    # Features: feature_1, feature_2, feature_3\n",
    "    X = df[['feature_1', 'feature_2', 'feature_3']].values\n",
    "    # Target: mds_updrs\n",
    "    y = df['mds_updrs'].values\n",
    "\n",
    "    # Train the LoLiMoT model\n",
    "    model = LoLiMoT(max_depth=5, min_error=1e-3, min_samples_split=2)  # Adjusted min_samples_split for small dataset\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    print(\"\\nModel Evaluation:\")\n",
    "    print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "\n",
    "    # Optional: Print the tree structure\n",
    "    print(\"\\nTree Structure:\")\n",
    "    model.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9a71825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\">CN2RSP</th>\n",
       "      <th colspan=\"4\" halign=\"left\">CN346RSP</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"4\" halign=\"left\">a_trait</th>\n",
       "      <th colspan=\"6\" halign=\"left\">SDMTOTAL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>BL</th>\n",
       "      <th>V04</th>\n",
       "      <th>V06</th>\n",
       "      <th>V08</th>\n",
       "      <th>V10</th>\n",
       "      <th>V12</th>\n",
       "      <th>BL</th>\n",
       "      <th>V04</th>\n",
       "      <th>V06</th>\n",
       "      <th>V08</th>\n",
       "      <th>...</th>\n",
       "      <th>V06</th>\n",
       "      <th>V08</th>\n",
       "      <th>V10</th>\n",
       "      <th>V12</th>\n",
       "      <th>BL</th>\n",
       "      <th>V04</th>\n",
       "      <th>V06</th>\n",
       "      <th>V08</th>\n",
       "      <th>V10</th>\n",
       "      <th>V12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PATNO</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.450980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>0.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3003</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.490196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3004</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60059</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60060</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.803922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60063</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65002</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>0.372549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90456</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.901961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>476 rows × 726 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CN2RSP                          CN346RSP                 ...  \\\n",
       "EVENT_ID     BL  V04  V06  V08  V10  V12       BL  V04  V06  V08  ...   \n",
       "PATNO                                                             ...   \n",
       "3000        0.0  0.0  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  ...   \n",
       "3001        0.0  0.0  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  ...   \n",
       "3002        0.0  0.0  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  ...   \n",
       "3003        0.0  0.0  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  ...   \n",
       "3004        0.0  0.0  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  ...   \n",
       "...         ...  ...  ...  ...  ...  ...      ...  ...  ...  ...  ...   \n",
       "60059       0.0  0.0  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  ...   \n",
       "60060       0.0  0.0  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  ...   \n",
       "60063       0.0  0.0  0.0  0.0  0.0  0.0      1.0  0.0  0.0  0.0  ...   \n",
       "65002       0.0  0.0  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  ...   \n",
       "90456       0.0  0.0  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  ...   \n",
       "\n",
       "           a_trait                                SDMTOTAL            \\\n",
       "EVENT_ID       V06       V08       V10       V12        BL       V04   \n",
       "PATNO                                                                  \n",
       "3000      0.371429  0.257143  0.371429  0.285714  0.294118  0.254902   \n",
       "3001      0.571429  0.314286  0.371429  0.542857  0.509804  0.627451   \n",
       "3002      0.657143  0.542857  0.685714  0.742857  0.529412  0.588235   \n",
       "3003      0.085714  0.228571  0.142857  0.114286  0.607843  0.666667   \n",
       "3004      0.257143  0.342857  0.228571  0.257143  0.411765  0.274510   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "60059     0.200000  0.142857  0.028571  0.571429  1.000000  1.000000   \n",
       "60060     0.314286  0.600000  0.542857  0.571429  0.882353  0.745098   \n",
       "60063     0.514286  0.885714  0.457143  0.800000  1.000000  1.000000   \n",
       "65002     0.771429  0.819048  0.866667  0.914286  0.647059  0.549020   \n",
       "90456     0.400000  0.142857  0.114286  0.342857  0.803922  0.921569   \n",
       "\n",
       "                                                  \n",
       "EVENT_ID       V06       V08       V10       V12  \n",
       "PATNO                                             \n",
       "3000      0.333333  0.294118  0.333333  0.294118  \n",
       "3001      0.509804  0.392157  0.392157  0.450980  \n",
       "3002      0.745098  0.470588  0.490196  0.588235  \n",
       "3003      0.568627  0.372549  0.509804  0.490196  \n",
       "3004      0.352941  0.431373  0.294118  0.333333  \n",
       "...            ...       ...       ...       ...  \n",
       "60059     1.000000  1.000000  1.000000  1.000000  \n",
       "60060     0.803922  0.705882  0.823529  0.803922  \n",
       "60063     1.000000  1.000000  1.000000  1.000000  \n",
       "65002     0.725490  0.607843  0.490196  0.372549  \n",
       "90456     0.803922  0.901961  0.921569  0.901961  \n",
       "\n",
       "[476 rows x 726 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Define paths\n",
    "PPMI_CLINICAL_GEN_DATA_DIR_INSIDE = Path('D:/data/raw/ppmi/behavior')\n",
    "dataset_name = '01_22_2024'\n",
    "PPMI_CLINICAL_GEN_DATA_DIR_INSIDE = PPMI_CLINICAL_GEN_DATA_DIR_INSIDE / 'dadu_etal_generated_data/clinical/ppmi'\n",
    "\n",
    "# Load preprocessed data\n",
    "preprocessed_data = pd.read_pickle(os.path.join(PPMI_CLINICAL_GEN_DATA_DIR_INSIDE, 'preprocessed', f\"{dataset_name}.pkl\"))\n",
    "\n",
    "# Load representation learning data\n",
    "representation_learning_data = pd.read_pickle(os.path.join(PPMI_CLINICAL_GEN_DATA_DIR_INSIDE, 'representation_learning', f\"{dataset_name}.pkl\"))\n",
    "\n",
    "# Load clustering data\n",
    "clustering_data = pd.read_pickle(os.path.join(PPMI_CLINICAL_GEN_DATA_DIR_INSIDE, 'clustering', f\"{dataset_name}.pkl\"))\n",
    "\n",
    "# Combine data\n",
    "input_data = {**preprocessed_data, **representation_learning_data, **clustering_data}\n",
    "datasets = input_data['data_names']\n",
    "dset_name = 'paper_experiment_flip_outlier'\n",
    "input_data['M_chosen'][dset_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2f92f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(preprocessed_data['M_chosen'][dset_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a2fff2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\">CN2RSP</th>\n",
       "      <th colspan=\"4\" halign=\"left\">CN346RSP</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"4\" halign=\"left\">a_trait</th>\n",
       "      <th colspan=\"6\" halign=\"left\">SDMTOTAL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>BL</th>\n",
       "      <th>V04</th>\n",
       "      <th>V06</th>\n",
       "      <th>V08</th>\n",
       "      <th>V10</th>\n",
       "      <th>V12</th>\n",
       "      <th>BL</th>\n",
       "      <th>V04</th>\n",
       "      <th>V06</th>\n",
       "      <th>V08</th>\n",
       "      <th>...</th>\n",
       "      <th>V06</th>\n",
       "      <th>V08</th>\n",
       "      <th>V10</th>\n",
       "      <th>V12</th>\n",
       "      <th>BL</th>\n",
       "      <th>V04</th>\n",
       "      <th>V06</th>\n",
       "      <th>V08</th>\n",
       "      <th>V10</th>\n",
       "      <th>V12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PATNO</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.450980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>0.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3003</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.490196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3004</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60059</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60060</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.803922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60063</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65002</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>0.372549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90456</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.901961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>476 rows × 726 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CN2RSP                          CN346RSP                 ...  \\\n",
       "EVENT_ID     BL  V04  V06  V08  V10  V12       BL  V04  V06  V08  ...   \n",
       "PATNO                                                             ...   \n",
       "3000        0.0  0.0  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  ...   \n",
       "3001        0.0  0.0  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  ...   \n",
       "3002        0.0  0.0  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  ...   \n",
       "3003        0.0  0.0  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  ...   \n",
       "3004        0.0  0.0  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  ...   \n",
       "...         ...  ...  ...  ...  ...  ...      ...  ...  ...  ...  ...   \n",
       "60059       0.0  0.0  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  ...   \n",
       "60060       0.0  0.0  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  ...   \n",
       "60063       0.0  0.0  0.0  0.0  0.0  0.0      1.0  0.0  0.0  0.0  ...   \n",
       "65002       0.0  0.0  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  ...   \n",
       "90456       0.0  0.0  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  ...   \n",
       "\n",
       "           a_trait                                SDMTOTAL            \\\n",
       "EVENT_ID       V06       V08       V10       V12        BL       V04   \n",
       "PATNO                                                                  \n",
       "3000      0.371429  0.257143  0.371429  0.285714  0.294118  0.254902   \n",
       "3001      0.571429  0.314286  0.371429  0.542857  0.509804  0.627451   \n",
       "3002      0.657143  0.542857  0.685714  0.742857  0.529412  0.588235   \n",
       "3003      0.085714  0.228571  0.142857  0.114286  0.607843  0.666667   \n",
       "3004      0.257143  0.342857  0.228571  0.257143  0.411765  0.274510   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "60059     0.200000  0.142857  0.028571  0.571429  1.000000  1.000000   \n",
       "60060     0.314286  0.600000  0.542857  0.571429  0.882353  0.745098   \n",
       "60063     0.514286  0.885714  0.457143  0.800000  1.000000  1.000000   \n",
       "65002     0.771429  0.819048  0.866667  0.914286  0.647059  0.549020   \n",
       "90456     0.400000  0.142857  0.114286  0.342857  0.803922  0.921569   \n",
       "\n",
       "                                                  \n",
       "EVENT_ID       V06       V08       V10       V12  \n",
       "PATNO                                             \n",
       "3000      0.333333  0.294118  0.333333  0.294118  \n",
       "3001      0.509804  0.392157  0.392157  0.450980  \n",
       "3002      0.745098  0.470588  0.490196  0.588235  \n",
       "3003      0.568627  0.372549  0.509804  0.490196  \n",
       "3004      0.352941  0.431373  0.294118  0.333333  \n",
       "...            ...       ...       ...       ...  \n",
       "60059     1.000000  1.000000  1.000000  1.000000  \n",
       "60060     0.803922  0.705882  0.823529  0.803922  \n",
       "60063     1.000000  1.000000  1.000000  1.000000  \n",
       "65002     0.725490  0.607843  0.490196  0.372549  \n",
       "90456     0.803922  0.901961  0.921569  0.901961  \n",
       "\n",
       "[476 rows x 726 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1658fa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_wide_format_updrs(df):\n",
    "    \"\"\"\n",
    "    Flattens multi-index column names into single-level column names.\n",
    "    Example: ('UPDRS', 'BL') becomes 'UPDRS_BL'\n",
    "    \"\"\"\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df.columns = [f\"{col[0]}_{col[1]}\" for col in df.columns]\n",
    "    return df\n",
    "\n",
    "def create_flattened_wide_format(df, columns_to_drop, target_column_name):\n",
    "    \"\"\"\n",
    "    Creates flattened wide format datasets where each dataset uses features from previous visits \n",
    "    to predict the target of the next visit.\n",
    "    \n",
    "    Example: For BL_V04, features are from BL, target is from V04\n",
    "            For BL_V04_V06, features are from BL and V04, target is from V06\n",
    "    \n",
    "    Returns:\n",
    "    list of tuples\n",
    "        Each tuple contains (name, features_df, target_series)\n",
    "    \"\"\"\n",
    "    wide_format_dataframe = modify_dataframe(df, columns_to_drop, target_column_name)\n",
    "    \n",
    "    prediction_scenarios = [\n",
    "        ('BL_V04', ['BL'], 'V04'),\n",
    "        ('BL_V04_V06', ['BL', 'V04'], 'V06'),\n",
    "        ('BL_V04_V06_V08', ['BL', 'V04', 'V06'], 'V08'),\n",
    "        ('BL_V04_V06_V08_V10', ['BL', 'V04', 'V06', 'V08'], 'V10'),\n",
    "        ('BL_V04_V06_V08_V10_V12', ['BL', 'V04', 'V06', 'V08', 'V10'], 'V12')\n",
    "    ]\n",
    "    \n",
    "    flattened_dataframes = []\n",
    "    \n",
    "    for name, feature_visits, target_visit in prediction_scenarios:\n",
    "        # Select feature columns from previous visits\n",
    "        feature_columns = [col for col in wide_format_dataframe.columns \n",
    "                         if any(visit in col for visit in feature_visits)]\n",
    "        \n",
    "        # Select target column from the target visit\n",
    "        target_column = [col for col in wide_format_dataframe.columns \n",
    "                        if target_visit in col and target_column_name in col][0]\n",
    "        \n",
    "        # Create separate feature DataFrame and target series\n",
    "        features_df = wide_format_dataframe[feature_columns]\n",
    "        target_series = wide_format_dataframe[target_column]\n",
    "        \n",
    "        # Flatten the features DataFrame\n",
    "        flat_features_df = flatten_wide_format_updrs(features_df)\n",
    "        \n",
    "        flattened_dataframes.append((name, flat_features_df, target_series))\n",
    "    \n",
    "    return flattened_dataframes\n",
    "\n",
    "# Usage example:\n",
    "# flattened_data = create_flattened_wide_format(df, columns_to_drop, target_column_name)\n",
    "# name, features_df, target = flattened_data[0]  # For BL_V04: features from BL, target from V04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3197de3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_24504\\1320272549.py:47: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  df = df.drop(columns=drop_column_names)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_24504\\1320272549.py:57: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  df = df.drop(columns=new_column_set)\n"
     ]
    }
   ],
   "source": [
    "flat_wide_format_updrs3 = create_flattened_wide_format(dataframe, ['UPDRS1', 'UPDRS2'], 'UPDRS3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1d3d5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "name, features_df, target = flat_wide_format_updrs3[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "05aa6488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BL_V04_V06_V08_V10_V12'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "715e1337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing dataset: BL_V04\n",
      "Testing parameters: {'max_depth': 3, 'min_error': 0.001, 'min_samples_split': 5}\n",
      "Testing parameters: {'max_depth': 3, 'min_error': 0.001, 'min_samples_split': 10}\n",
      "Testing parameters: {'max_depth': 3, 'min_error': 0.001, 'min_samples_split': 15}\n",
      "Testing parameters: {'max_depth': 3, 'min_error': 0.0001, 'min_samples_split': 5}\n",
      "Testing parameters: {'max_depth': 3, 'min_error': 0.0001, 'min_samples_split': 10}\n",
      "Testing parameters: {'max_depth': 3, 'min_error': 0.0001, 'min_samples_split': 15}\n",
      "Testing parameters: {'max_depth': 5, 'min_error': 0.001, 'min_samples_split': 5}\n",
      "Testing parameters: {'max_depth': 5, 'min_error': 0.001, 'min_samples_split': 10}\n",
      "Testing parameters: {'max_depth': 5, 'min_error': 0.001, 'min_samples_split': 15}\n",
      "Testing parameters: {'max_depth': 5, 'min_error': 0.0001, 'min_samples_split': 5}\n",
      "Testing parameters: {'max_depth': 5, 'min_error': 0.0001, 'min_samples_split': 10}\n",
      "Testing parameters: {'max_depth': 5, 'min_error': 0.0001, 'min_samples_split': 15}\n",
      "Testing parameters: {'max_depth': 7, 'min_error': 0.001, 'min_samples_split': 5}\n",
      "Testing parameters: {'max_depth': 7, 'min_error': 0.001, 'min_samples_split': 10}\n",
      "Testing parameters: {'max_depth': 7, 'min_error': 0.001, 'min_samples_split': 15}\n",
      "Testing parameters: {'max_depth': 7, 'min_error': 0.0001, 'min_samples_split': 5}\n",
      "Testing parameters: {'max_depth': 7, 'min_error': 0.0001, 'min_samples_split': 10}\n",
      "Testing parameters: {'max_depth': 7, 'min_error': 0.0001, 'min_samples_split': 15}\n",
      "\n",
      "Best parameters for BL_V04:\n",
      "{'max_depth': 7, 'min_error': 0.001, 'min_samples_split': 5}\n",
      "\n",
      "Results for BL_V04 with best parameters:\n",
      "CV Training Set Metrics (averaged over folds):\n",
      "MAE: 0.000\n",
      "RMSE: 0.000\n",
      "R²: 1.000\n",
      "CV Test Set Metrics (averaged over folds):\n",
      "MAE: 13.058\n",
      "RMSE: 34.720\n",
      "R²: -160.096\n",
      "\n",
      "Processing dataset: BL_V04_V06\n",
      "Testing parameters: {'max_depth': 3, 'min_error': 0.001, 'min_samples_split': 5}\n",
      "Testing parameters: {'max_depth': 3, 'min_error': 0.001, 'min_samples_split': 10}\n",
      "Testing parameters: {'max_depth': 3, 'min_error': 0.001, 'min_samples_split': 15}\n",
      "Testing parameters: {'max_depth': 3, 'min_error': 0.0001, 'min_samples_split': 5}\n",
      "Testing parameters: {'max_depth': 3, 'min_error': 0.0001, 'min_samples_split': 10}\n",
      "Testing parameters: {'max_depth': 3, 'min_error': 0.0001, 'min_samples_split': 15}\n",
      "Testing parameters: {'max_depth': 5, 'min_error': 0.001, 'min_samples_split': 5}\n",
      "Testing parameters: {'max_depth': 5, 'min_error': 0.001, 'min_samples_split': 10}\n",
      "Testing parameters: {'max_depth': 5, 'min_error': 0.001, 'min_samples_split': 15}\n",
      "Testing parameters: {'max_depth': 5, 'min_error': 0.0001, 'min_samples_split': 5}\n",
      "Testing parameters: {'max_depth': 5, 'min_error': 0.0001, 'min_samples_split': 10}\n",
      "Testing parameters: {'max_depth': 5, 'min_error': 0.0001, 'min_samples_split': 15}\n",
      "Testing parameters: {'max_depth': 7, 'min_error': 0.001, 'min_samples_split': 5}\n",
      "Testing parameters: {'max_depth': 7, 'min_error': 0.001, 'min_samples_split': 10}\n",
      "Testing parameters: {'max_depth': 7, 'min_error': 0.001, 'min_samples_split': 15}\n",
      "Testing parameters: {'max_depth': 7, 'min_error': 0.0001, 'min_samples_split': 5}\n",
      "Testing parameters: {'max_depth': 7, 'min_error': 0.0001, 'min_samples_split': 10}\n",
      "Testing parameters: {'max_depth': 7, 'min_error': 0.0001, 'min_samples_split': 15}\n",
      "\n",
      "Best parameters for BL_V04_V06:\n",
      "{'max_depth': 3, 'min_error': 0.001, 'min_samples_split': 5}\n",
      "\n",
      "Results for BL_V04_V06 with best parameters:\n",
      "CV Training Set Metrics (averaged over folds):\n",
      "MAE: 0.000\n",
      "RMSE: 0.000\n",
      "R²: 1.000\n",
      "CV Test Set Metrics (averaged over folds):\n",
      "MAE: 5.410\n",
      "RMSE: 7.762\n",
      "R²: -1.523\n",
      "\n",
      "Processing dataset: BL_V04_V06_V08\n",
      "Testing parameters: {'max_depth': 3, 'min_error': 0.001, 'min_samples_split': 5}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24504\\2197340564.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[1;31m# Train model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLoLiMoT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m                 \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[1;31m# Get predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24504\\3379290294.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \"\"\"\n\u001b[0;32m     37\u001b[0m         \u001b[1;31m# Start recursion with the whole dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_recursive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit_recursive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24504\\3379290294.py\u001b[0m in \u001b[0;36m_fit_recursive\u001b[1;34m(self, X, y, depth)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;31m# Find the best feature and value to split the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0mbest_split_feature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_split_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_find_best_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;31m# If no significant improvement is found, make this a leaf node\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24504\\3379290294.py\u001b[0m in \u001b[0;36m_find_best_split\u001b[1;34m(self, X, y, current_model)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m                 \u001b[0mleft_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mleft_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mleft_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m                 \u001b[0mright_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mright_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mright_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m                 \u001b[1;31m# Calculate the combined error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5],\n",
    "    'min_error': [1e-3, 1e-4],\n",
    "    'min_samples_split': [5, 10]\n",
    "}\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = {\n",
    "    'Dataset': [],\n",
    "    'Best_max_depth': [],\n",
    "    'Best_min_error': [],\n",
    "    'Best_min_samples_split': [],\n",
    "    'CV_Train_MAE': [],\n",
    "    'CV_Train_RMSE': [],\n",
    "    'CV_Train_R2': [],\n",
    "    'CV_Test_MAE': [],\n",
    "    'CV_Test_RMSE': [],\n",
    "    'CV_Test_R2': []\n",
    "}\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Run grid search with cross-validation for each dataset\n",
    "for name, X, y in flat_wide_format_updrs3:\n",
    "    print(f\"\\nProcessing dataset: {name}\")\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    X = X.to_numpy()\n",
    "    y = y.to_numpy()\n",
    "    \n",
    "    # Initialize variables for grid search\n",
    "    best_avg_test_rmse = float('inf')\n",
    "    best_params = None\n",
    "    \n",
    "    # Generate all parameter combinations\n",
    "    param_combinations = [dict(zip(param_grid.keys(), v)) \n",
    "                        for v in product(*param_grid.values())]\n",
    "    \n",
    "    # Grid search with cross-validation\n",
    "    for params in param_combinations:\n",
    "        print(f\"Testing parameters: {params}\")\n",
    "        \n",
    "        # Store metrics for each fold\n",
    "        fold_train_mae = []\n",
    "        fold_train_rmse = []\n",
    "        fold_train_r2 = []\n",
    "        fold_test_mae = []\n",
    "        fold_test_rmse = []\n",
    "        fold_test_r2 = []\n",
    "        \n",
    "        try:\n",
    "            # Perform k-fold cross-validation\n",
    "            for fold_idx, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
    "                X_train, X_test = X[train_idx], X[test_idx]\n",
    "                y_train, y_test = y[train_idx], y[test_idx]\n",
    "                \n",
    "                # Train model\n",
    "                model = LoLiMoT(**params)\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                # Get predictions\n",
    "                y_train_pred = model.predict(X_train)\n",
    "                y_test_pred = model.predict(X_test)\n",
    "                \n",
    "                # Calculate metrics\n",
    "                fold_train_mae.append(mean_absolute_error(y_train, y_train_pred))\n",
    "                fold_train_rmse.append(np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "                fold_train_r2.append(r2_score(y_train, y_train_pred))\n",
    "                \n",
    "                fold_test_mae.append(mean_absolute_error(y_test, y_test_pred))\n",
    "                fold_test_rmse.append(np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "                fold_test_r2.append(r2_score(y_test, y_test_pred))\n",
    "            \n",
    "            # Calculate average metrics across folds\n",
    "            avg_test_rmse = np.mean(fold_test_rmse)\n",
    "            \n",
    "            # Update best parameters if current model is better\n",
    "            if avg_test_rmse < best_avg_test_rmse:\n",
    "                best_avg_test_rmse = avg_test_rmse\n",
    "                best_params = params\n",
    "                best_metrics = {\n",
    "                    'train_mae': np.mean(fold_train_mae),\n",
    "                    'train_rmse': np.mean(fold_train_rmse),\n",
    "                    'train_r2': np.mean(fold_train_r2),\n",
    "                    'test_mae': np.mean(fold_test_mae),\n",
    "                    'test_rmse': np.mean(fold_test_rmse),\n",
    "                    'test_r2': np.mean(fold_test_r2)\n",
    "                }\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error with parameters {params}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\nBest parameters for {name}:\")\n",
    "    print(best_params)\n",
    "    \n",
    "    # Store results\n",
    "    results['Dataset'].append(name)\n",
    "    results['Best_max_depth'].append(best_params['max_depth'])\n",
    "    results['Best_min_error'].append(best_params['min_error'])\n",
    "    results['Best_min_samples_split'].append(best_params['min_samples_split'])\n",
    "    results['CV_Train_MAE'].append(round(best_metrics['train_mae'], 3))\n",
    "    results['CV_Train_RMSE'].append(round(best_metrics['train_rmse'], 3))\n",
    "    results['CV_Train_R2'].append(round(best_metrics['train_r2'], 3))\n",
    "    results['CV_Test_MAE'].append(round(best_metrics['test_mae'], 3))\n",
    "    results['CV_Test_RMSE'].append(round(best_metrics['test_rmse'], 3))\n",
    "    results['CV_Test_R2'].append(round(best_metrics['test_r2'], 3))\n",
    "    \n",
    "    # Print current results\n",
    "    print(f\"\\nResults for {name} with best parameters:\")\n",
    "    print(f\"CV Training Set Metrics (averaged over folds):\")\n",
    "    print(f\"MAE: {best_metrics['train_mae']:.3f}\")\n",
    "    print(f\"RMSE: {best_metrics['train_rmse']:.3f}\")\n",
    "    print(f\"R²: {best_metrics['train_r2']:.3f}\")\n",
    "    print(f\"CV Test Set Metrics (averaged over folds):\")\n",
    "    print(f\"MAE: {best_metrics['test_mae']:.3f}\")\n",
    "    print(f\"RMSE: {best_metrics['test_rmse']:.3f}\")\n",
    "    print(f\"R²: {best_metrics['test_r2']:.3f}\")\n",
    "\n",
    "# Create DataFrame with results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save to Excel\n",
    "results_df.to_excel('lolimot_exp_result_grid_search_5cv.xlsx', index=False)\n",
    "\n",
    "# Display final results table\n",
    "print(\"\\nFinal Results:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603a7990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06245576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c960ae6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8963407a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae53299b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5a29eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb0cb0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dc5f66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_drop_target_from_wide_format(df, target_column_name, visit):\n",
    "    # Extract the target column\n",
    "    target_column = df[(target_column_name, visit)]\n",
    "    \n",
    "    # Drop the target column from the main dataframe\n",
    "    df = df.drop(columns=[(target_column_name, visit)])\n",
    "    \n",
    "    return df, target_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd2dc723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_updrs_2_3_4_from_wide_format(df):\n",
    "    updrs2_columns = [\"NP2SPCH\", \"NP2SALV\", \"NP2SWAL\", \"NP2EAT\", \"NP2DRES\", \"NP2HYGN\", \"NP2HWRT\",\n",
    "                  \"NP2HOBB\", \"NP2TURN\", \"NP2TRMR\", \"NP2RISE\", \"NP2WALK\", \"NP2FREZ\"]\n",
    "    \n",
    "# \"['CMEDTM', 'EXAMTM', 'PN3RIGRL', 'DYSKPRES', 'DYSKIRAT', 'ANNUAL_TIME_BTW_DOSE_NUPDRS', 'ON_OFF_DOSE', 'PD_MED_USE']\n",
    "    updrs3_columns = [\"NP3SPCH\", \"NP3FACXP\", \"NP3RIGN\", \"NP3RIGRU\", \"NP3RIGLU\", \"NP3RIGLL\",\n",
    "                  \"NP3FTAPR\", \"NP3FTAPL\", \"NP3HMOVR\", \"NP3HMOVL\", \"NP3PRSPR\", \"NP3PRSPL\", \"NP3TTAPR\", \"NP3TTAPL\", \"NP3LGAGR\",\n",
    "                  \"NP3LGAGL\", \"NP3RISNG\", \"NP3GAIT\", \"NP3FRZGT\", \"NP3PSTBL\", \"NP3POSTR\", \"NP3BRADY\", \"NP3PTRMR\", \"NP3PTRML\",\n",
    "                  \"NP3KTRMR\", \"NP3KTRML\", \"NP3RTARU\", \"NP3RTALU\", \"NP3RTARL\", \"NP3RTALL\", \"NP3RTALJ\", \"NP3RTCON\",\n",
    "                   \"NHY\"]\n",
    "\n",
    "#     updrs4_columns = [\"NP4WDYSK\", \"NP4DYSKI\", \"NP4OFF\", \"NP4FLCTI\", \"NP4FLCTX\", \"NP4DYSTN\"]\n",
    "    df = df.drop(columns=updrs2_columns + updrs3_columns)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_updrs1_column_in_wide_format(df):\n",
    "    updrs1_columns = ['NP1COG', 'NP1HALL', 'NP1DPRS', 'NP1ANXS', 'NP1APAT', 'NP1DDS',\n",
    "                      'NP1SLPN', 'NP1SLPD', 'NP1PAIN', 'NP1URIN', 'NP1CNST', 'NP1LTHD', 'NP1FATG']\n",
    "    \n",
    "    updrs1_multiindex = pd.MultiIndex.from_product([['UPDRS1'], df.columns.levels[1]], names=df.columns.names)\n",
    "\n",
    "    updrs1_df = pd.DataFrame(index=df.index, columns=updrs1_multiindex)\n",
    "    \n",
    "    for visit in df.columns.levels[1]:\n",
    "        updrs1_df[('UPDRS1', visit)] = df.loc[:, (updrs1_columns, visit)].sum(axis=1)\n",
    "    \n",
    "    df = df.drop(columns=updrs1_columns)\n",
    "    \n",
    "    df = pd.concat([df, updrs1_df], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def modify_dataframe(df, columns_to_drop, new_column_name):\n",
    "\n",
    "    updrs_columns = {\n",
    "        'UPDRS1': ['NP1COG', 'NP1HALL', 'NP1DPRS', 'NP1ANXS', 'NP1APAT', 'NP1DDS', 'NP1SLPN', 'NP1SLPD', 'NP1PAIN', 'NP1URIN', 'NP1CNST', 'NP1LTHD', 'NP1FATG'],\n",
    "        'UPDRS2': ['NP2SPCH', 'NP2SALV', 'NP2SWAL', 'NP2EAT', 'NP2DRES', 'NP2HYGN', 'NP2HWRT', 'NP2HOBB', 'NP2TURN', 'NP2TRMR', 'NP2RISE', 'NP2WALK', 'NP2FREZ'],\n",
    "        'UPDRS3': ['NP3SPCH', 'NP3FACXP', 'NP3RIGN', 'NP3RIGRU', 'NP3RIGLU', 'NP3RIGLL', 'NP3FTAPR', 'NP3FTAPL', 'NP3HMOVR', 'NP3HMOVL', 'NP3PRSPR', 'NP3PRSPL', 'NP3TTAPR', 'NP3TTAPL', 'NP3LGAGR', 'NP3LGAGL', 'NP3RISNG', 'NP3GAIT', 'NP3FRZGT', 'NP3PSTBL', 'NP3POSTR', 'NP3BRADY', 'NP3PTRMR', 'NP3PTRML', 'NP3KTRMR', 'NP3KTRML', 'NP3RTARU', 'NP3RTALU', 'NP3RTARL', 'NP3RTALL', 'NP3RTALJ', 'NP3RTCON', 'NHY']\n",
    "        #'UPDRS4': ['NP4WDYSK', 'NP4DYSKI', 'NP4OFF', 'NP4FLCTI', 'NP4FLCTX', 'NP4DYSTN']\n",
    "    }\n",
    "    \n",
    "    drop_column_names = []\n",
    "    for drop_target in columns_to_drop:\n",
    "            drop_column_names.extend(updrs_columns[drop_target])\n",
    "    \n",
    "    df = df.drop(columns=drop_column_names)\n",
    "    \n",
    "    if new_column_name in updrs_columns:\n",
    "        new_column_set = updrs_columns[new_column_name]\n",
    "        new_column_multiindex = pd.MultiIndex.from_product([[new_column_name], df.columns.levels[1]], names=df.columns.names)\n",
    "        new_column_df = pd.DataFrame(index=df.index, columns=new_column_multiindex)\n",
    "        \n",
    "        for visit in df.columns.levels[1]:\n",
    "            new_column_df[(new_column_name, visit)] = df.loc[:, (new_column_set, visit)].sum(axis=1)\n",
    "        \n",
    "        df = df.drop(columns=new_column_set)\n",
    "        df = pd.concat([df, new_column_df], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47078b87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b564e6b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd06f8f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae165ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
